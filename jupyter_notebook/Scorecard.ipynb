{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fdd491",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180479ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import chi2_contingency\n",
    "import scorecardpy as sc\n",
    "import random as rd\n",
    "import re\n",
    "from IPython.display import display\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8140bf9",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc39c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data prepare ------\n",
    "# load germancredit data\n",
    "smp_full = sc.germancredit()\n",
    "smp_full['will_default'] = smp_full['creditability'].apply(lambda x: 1 if x == 'bad' else 0)\n",
    "smp_full = smp_full.loc[:,smp_full.columns != 'creditability']\n",
    "smp_full.loc[0:99, 'credit.amount'] = np.nan\n",
    "smp_full.loc[0:99, 'purpose'] = np.nan\n",
    "\n",
    "for i in range(5):\n",
    "    smp_full = pd.concat([smp_full, smp_full])\n",
    "smp_full['RepDate_End'] = np.random.randint(1, 73, smp_full.shape[0])\n",
    "smp_full = smp_full.reset_index(drop=True)\n",
    "\n",
    "smp_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d9f31",
   "metadata": {},
   "source": [
    "# 1. Preliminary analysis of variables (missings, outliers, concentration/distribution) - based on smp_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae74a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that are not variables\n",
    "var_skip = ['will_default','RepDate_End']\n",
    "# special values for numeric variables - TBD\n",
    "spl_val = []\n",
    "# list of variables by type (numeric variables with less than 10 unique values are considered as categorical)\n",
    "var_cat, var_num = sc.var_types(smp_full, var_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap for the missing values\n",
    "percent_missing = smp_full.loc[:, var_cat+var_num].isna().sum() * 100 / len(smp_full)\n",
    "percent_missing = pd.DataFrame({'column':percent_missing.index, 'percent_missing':percent_missing.values})\n",
    "percent_missing.sort_values('percent_missing', ascending=False, inplace=True)\n",
    "percent_missing.reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(smp_full[percent_missing.column].isna().transpose(),\n",
    "            cmap=\"YlGnBu\",\n",
    "            cbar_kws={'label': 'Missing Data'})\n",
    "plt.savefig(\"1_1_missings_heatmap.png\", dpi=100, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70e34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#round missings\n",
    "#thresholds as params\n",
    "# warning checks\n",
    "var_cat_summary, var_num_summary = sc.var_pre_analysis(smp_full, var_cat, var_num, spl_val, hhi_low=0.05, hhi_high=0.95, min_share=0.05)\n",
    "\n",
    "writer = pd.ExcelWriter('1_2_preliminary_analysis.xlsx', engine='xlsxwriter')\n",
    "var_cat_summary.to_excel(writer, sheet_name='var_cat_summary')\n",
    "var_num_summary.to_excel(writer, sheet_name='var_num_summary')\n",
    "writer.save()\n",
    "\n",
    "display(var_cat_summary)\n",
    "display(var_num_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#treatment of nan\n",
    "for var, dt in smp_full.dtypes.items():\n",
    "    if var not in var_skip and smp_full[var].isna().sum() > 0:\n",
    "        print(var,smp_full[var].isna().sum()) \n",
    "        if dt.name == 'category':\n",
    "            smp_full[var] = smp_full[var].cat.add_categories('Missing').fillna('Missing')\n",
    "            print('Missing')\n",
    "        if dt.name == 'object':\n",
    "            smp_full[var] = smp_full[var].fillna('Missing')\n",
    "            print('Missing')\n",
    "        else: \n",
    "            print(smp_full[var].median())\n",
    "            smp_full[var] = smp_full[var].fillna(smp_full[var].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70348361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# distribution for categorical variables with extract to pdf\n",
    "sc.var_cat_distr(smp_full, var_cat, '1_3_categorical_vars_distribution.pdf', groupby='foreign.worker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8be1be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.var_num_distr(smp_full, var_num, '1_4_numerical_vars_distribution.pdf', groupby='foreign.worker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c061f",
   "metadata": {},
   "source": [
    "# 2. Development sample creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad4a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of the development window \n",
    "sorted_date = sorted(smp_full['RepDate_End'].unique())\n",
    "del sorted_date[-12:]\n",
    "smp_dev = smp_full.loc[smp_full['RepDate_End'].isin(sorted_date)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7bf045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check target\n",
    "smp_dev['target'] = smp_dev['will_default']\n",
    "smp_dev.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29034669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of variables that will be used for the development\n",
    "smp_dev = smp_dev[var_cat+var_num+['target']+['RepDate_End']]\n",
    "\n",
    "#smp_dev = smp_full.loc[smp_dev['prod_grp'] == 'Mortgage']\n",
    "\n",
    "# train/test split as 80/20\n",
    "train, test = sc.split_df(smp_dev, ratio=0.8, seed=123).values()\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7704c2b0",
   "metadata": {},
   "source": [
    "# 3. Automated binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning\n",
    "fine_class, coarse_class = sc.woebin(train, y = 'target', x = var_cat + var_num, init_count_distr = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513014bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting binning results to excel\n",
    "pd.concat(fine_class.values()).reset_index(drop=True).to_excel('3_1_fine_classing.xlsx')\n",
    "pd.concat(coarse_class.values()).reset_index(drop=True).to_excel('3_2_coarse_classing_auto.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ca600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv for variables after automated binning\n",
    "coarse_class_iv = sc.vars_iv(var_cat + var_num, coarse_class)\n",
    "coarse_class_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning visualization\n",
    "sc.woebin_plot(coarse_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d7209c",
   "metadata": {},
   "source": [
    "# 4. Binning adjustments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30582849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# manual review and adjustment of binning\n",
    "breaks_list = sc.woebin_adj(train, y=\"target\", bins=coarse_class, fine_bins=fine_class, adj_all_var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57da7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update of coarse classing table (fine classing is relevant only for automated binning)\n",
    "fine_class_adj, coarse_class_adj = sc.woebin(train, y = 'target', x = var_cat + var_num, breaks_list = breaks_list, init_count_distr = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying woe transformations on train and test samples \n",
    "train_woe = sc.woebin_ply(train, bins=coarse_class_adj)\n",
    "test_woe = sc.woebin_ply(test, bins=coarse_class_adj)\n",
    "# defining woe variables\n",
    "vars_woe = []\n",
    "for i in var_cat+var_num:\n",
    "    vars_woe.append(i+'_woe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9364ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.iv_group(train_woe, vars_woe, groupby='RepDate_End')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4835cd3",
   "metadata": {},
   "source": [
    "# 5. Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8783b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_woe[vars_woe].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting correlation heatmap\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(train_woe[vars_woe].corr(), cmap=\"YlGnBu\", annot=True)\n",
    "  \n",
    "# displaying heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc9fef",
   "metadata": {},
   "source": [
    "# 6. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and variables\n",
    "y_train = train_woe['target']\n",
    "X_train = train_woe[vars_woe]\n",
    "y_test = test_woe['target']\n",
    "X_test = test_woe[vars_woe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression ------\n",
    "lr = LogisticRegression(penalty='l1', C=0.9, solver='saga', n_jobs=-1)\n",
    "lr.fit(X_train, y_train)\n",
    "# lr.coef_\n",
    "# lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb0347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted proability\n",
    "train_pred = lr.predict_proba(X_train)[:,1]\n",
    "test_pred = lr.predict_proba(X_test)[:,1]\n",
    "# performance ks & roc ------\n",
    "train_perf = sc.perf_eva(y_train, train_pred, title = \"train\")\n",
    "test_perf = sc.perf_eva(y_test, test_pred, title = \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18edb9b",
   "metadata": {},
   "source": [
    "# 7. Initial calibration and scorecard points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score ------\n",
    "card = sc.scorecard(coarse_class_adj, lr, X_train.columns, start_zero=True)\n",
    "# credit score\n",
    "train_score  = sc.scorecard_ply(train, card, print_step=0)\n",
    "test_score = sc.scorecard_ply(test, card, print_step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard_points = pd.concat(card, ignore_index=True)\n",
    "scorecard_points.to_excel(\"scorecard_points.xlsx\", sheet_name='scorecard_points')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
