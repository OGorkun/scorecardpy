{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6aae60",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ebf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import chi2_contingency\n",
    "import scorecardpy as sc\n",
    "from scorecardpy.LogisticRegStats import LogisticRegStats\n",
    "import random as rd\n",
    "import re\n",
    "from IPython.display import display\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa21b6",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prepare ------\n",
    "# load germancredit data\n",
    "smp_full = sc.germancredit()\n",
    "smp_full['target'] = smp_full['creditability'].apply(lambda x: 1 if x == 'bad' else 0)\n",
    "smp_full.loc[0:99, 'credit.amount'] = np.nan\n",
    "smp_full.loc[100:199, 'credit.amount'] = -9999\n",
    "smp_full['credit.amount.corr'] = smp_full['credit.amount']*2 - 1000\n",
    "smp_full.loc[0:99, 'purpose'] = np.nan\n",
    "smp_full.loc[100:109, 'target'] = np.nan\n",
    "\n",
    "# Artificially multiplying the dataset\n",
    "for i in range(5):\n",
    "    smp_full = pd.concat([smp_full, smp_full])\n",
    "\n",
    "# Generate a list of all month-end dates between Jan 2020 and Sep 2025\n",
    "month_ends = pd.date_range(start=\"2020-01-31\", end=\"2025-09-30\", freq=\"ME\")\n",
    "\n",
    "# Randomly assign one of these month-end dates to each row\n",
    "np.random.seed(123)\n",
    "smp_full[\"RepDate_end\"] = np.random.choice(month_ends, size=smp_full.shape[0])\n",
    "smp_full = smp_full.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d718b37",
   "metadata": {},
   "source": [
    "# 1. Preliminary analysis of variables (missings, outliers, concentration/distribution) - based on smp_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb7216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# good/bad label\n",
    "target = \"target\"\n",
    "\n",
    "# date column (e.g. snapshot date or application date)\n",
    "date = \"RepDate_end\"\n",
    "\n",
    "# other columns that are not variables\n",
    "var_skip = [\"creditability\"]\n",
    "\n",
    "# special values for numeric variables\n",
    "special_values = [-9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee83c36-e411-4315-be8c-bdcaa871292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns that are not variables\n",
    "var_skip_all = var_skip + [target, date]\n",
    "\n",
    "# variables checks summary - output to Excel\n",
    "var_cat_summary, var_num_summary, var_list = sc.expl_analysis(\n",
    "    smp_full, var_skip_all, special_values\n",
    ")\n",
    "\n",
    "# heatmap for the missing values\n",
    "sc.miss_heatmap(smp_full, var_skip, fig_width=10, fig_height=len(var_list)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f668b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # variables distribution - TBD - only for numerical vars\n",
    "# sc.var_distr(smp_full, ['age.in.years'], groupby = target, special_values = special_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of shares of missings and bads in target over time\n",
    "def nan_rate(target):\n",
    "    return sum(np.isnan(target)) / len(target)\n",
    "\n",
    "def bad_rate(target):\n",
    "    return sum(target == 1) / (sum(target == 0) + sum(target == 1))\n",
    "\n",
    "target_ot = smp_full.groupby(date)[target].agg([nan_rate, bad_rate])\n",
    "\n",
    "# bad rate over time\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(target_ot.index, target_ot[\"bad_rate\"], marker=\"o\", linestyle=\"-\", color=\"steelblue\")\n",
    "ax.set_title(\"Bad Rate Over Time\", fontsize=14)\n",
    "ax.set_xlabel(\"Date\", fontsize=12)\n",
    "ax.set_ylabel(\"Bad Rate\", fontsize=12)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# dates with blank target\n",
    "pd.DataFrame(target_ot[target_ot[\"nan_rate\"] > 0][\"nan_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa98a7",
   "metadata": {},
   "source": [
    "# 2. Development sample creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of the development window\n",
    "smp_dev = smp_full[smp_full[date].between('2020-01-31', '2024-06-30')]\n",
    "\n",
    "# selection of variables that will be used for the development\n",
    "smp_dev = smp_dev[var_list + [target, date]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a603d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check target\n",
    "print(smp_dev.groupby(target, dropna=False).size())\n",
    "# delete records with blank target\n",
    "smp_dev = smp_dev[smp_dev[target].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153fe7c-c1aa-47ed-b004-c50a6d17394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split as 80/20\n",
    "train, test = sc.split_df(smp_dev, ratio=0.8, seed=123).values()\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "# train/test sample size\n",
    "sample_summary = pd.concat([\n",
    "    pd.Series({\"sample\": \"train\", \"bads\": train[target].sum(), \"obs\": train[target].count()}),\n",
    "    pd.Series({\"sample\": \"test\", \"bads\": test[target].sum(), \"obs\": test[target].count()})\n",
    "], axis=1).T\n",
    "sample_summary[\"BR\"] = sample_summary[\"bads\"] / sample_summary[\"obs\"]\n",
    "sample_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae9f54",
   "metadata": {},
   "source": [
    "# 3. Automated binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min bin size for fine classing\n",
    "min_perc_fine_bin = 0.05\n",
    "\n",
    "# min bin size for coarse classing\n",
    "count_distr_limit = 0.05\n",
    "\n",
    "# max number of coarse classes\n",
    "bin_num_limit = int(1 / count_distr_limit)\n",
    "\n",
    "# number of decimals for bin intervals\n",
    "bin_decimals = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8583828",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_inf = []\n",
    "# binning\n",
    "fine_class, coarse_class = sc.woebin(\n",
    "    train,\n",
    "    y=target,\n",
    "    # x = [\"age_in_years\", \"status_of_existing_checking_account\", \"foreign_worker\"],\n",
    "    var_skip=var_skip_all + var_inf,\n",
    "    special_values=special_values,\n",
    "    min_perc_fine_bin=min_perc_fine_bin,\n",
    "    count_distr_limit=count_distr_limit,\n",
    "    bin_num_limit=bin_num_limit,\n",
    "    print_step=10,\n",
    "    ignore_datetime_cols=False,\n",
    "    bin_decimals=bin_decimals,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automated filtering of variables using iv and correlation from the fine classing\n",
    "var_list, var_rej_fine = sc.vars_filter(\n",
    "    train, fine_class, corr_threshold=0.6, iv_threshold=0.1\n",
    ")\n",
    "\n",
    "# removing excluded variables from coarse_class dictionary\n",
    "coarse_class_filt = {k: v for k, v in coarse_class.items() if k in var_list}\n",
    "\n",
    "# binning to df\n",
    "fine_class_df = pd.concat(fine_class.values()).reset_index(drop=True)\n",
    "coarse_class_df = pd.concat(coarse_class.values()).reset_index(drop=True)\n",
    "\n",
    "# iv for variables after automated binning\n",
    "fine_class_iv = sc.vars_iv(fine_class)\n",
    "coarse_class_iv = sc.vars_iv(coarse_class)\n",
    "coarse_class_filt_iv = sc.vars_iv(coarse_class_filt)\n",
    "\n",
    "# exctracting results to Excel\n",
    "with pd.ExcelWriter(Path(\"3_1_automated_binning.xlsx\"), engine=\"xlsxwriter\") as writer:\n",
    "    fine_class_df.to_excel(writer, sheet_name=\"fine_classing\", index=False)\n",
    "    coarse_class_df.to_excel(writer, sheet_name=\"coarse_classing\", index=False)\n",
    "    fine_class_iv.to_excel(writer, sheet_name=\"fine_class_iv\", index=False)\n",
    "    coarse_class_iv.to_excel(writer, sheet_name=\"coarse_class_iv\", index=False)\n",
    "    var_rej_fine.to_excel(writer, sheet_name=\"rejected_vars_fine_class\", index=False)\n",
    "    coarse_class_filt_iv.to_excel(writer, sheet_name=\"coarse_class_filt_iv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928bc155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # binning visualization\n",
    "# var_show = ['status.of.existing.checking.account', 'credit.history','property']\n",
    "# coarse_class_selected = {}\n",
    "# # coarse_class_show = {k: v for k, v in coarse_class.items() if k in var_show}\n",
    "# for k in var_show:\n",
    "#     coarse_class_selected[k] = coarse_class[k]\n",
    "# sc.woebin_plot(coarse_class_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea05222",
   "metadata": {},
   "source": [
    "# 4. Binning adjustments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be212913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual review and adjustment of binning (results are being saved to save_breaks_list and can be loaded from load_breaks_list)\n",
    "breaks_list = sc.woebin_adj(\n",
    "    train,\n",
    "    y=target,\n",
    "    # x = ['N103_1'],\n",
    "    load_breaks_list=\"4_1_breaks_list_adj.py\",\n",
    "    save_breaks_list=\"4_1_breaks_list_adj.py\",\n",
    "    bins=coarse_class_filt,  # used in case load_breaks_list is None or not exists\n",
    "    init_bins=fine_class,\n",
    "    adj_all_var=False,  # False - only non-monotonic woe variables\n",
    "    show_init_bins=True,  # True - to show the table with Fine classing results\n",
    "    special_values=special_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_trend_excl = [\n",
    "    'credit.amount',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse classing after manual adjustments\n",
    "_, coarse_class_adj = sc.woebin(\n",
    "    train,\n",
    "    y=target,\n",
    "    x=list(eval(breaks_list).keys()),\n",
    "    breaks_list=breaks_list,\n",
    "    var_skip=vars_trend_excl,\n",
    "    special_values=special_values,\n",
    "    min_perc_fine_bin=min_perc_fine_bin,\n",
    "    count_distr_limit=count_distr_limit,\n",
    "    bin_num_limit=bin_num_limit,\n",
    "    print_step=10,\n",
    "    ignore_datetime_cols=False,\n",
    "    bin_decimals=bin_decimals,\n",
    ")\n",
    "\n",
    "# exctracting results to Excel\n",
    "coarse_class_adj_df = pd.concat(coarse_class_adj.values()).reset_index(drop=True)\n",
    "coarse_class_adj_iv = sc.vars_iv(coarse_class_adj)\n",
    "\n",
    "with pd.ExcelWriter(Path(\"4_2_binning_adjustments.xlsx\"), engine=\"xlsxwriter\") as writer:\n",
    "    coarse_class_adj_df.to_excel(writer, sheet_name=\"coarse_class_adj\", index=False)\n",
    "    coarse_class_adj_iv.to_excel(writer, sheet_name=\"coarse_class_adj_iv\", index=False)\n",
    "    \n",
    "# applying woe transformations on train and test samples\n",
    "train_woe = sc.woebin_ply(train, bins=coarse_class_adj)\n",
    "test_woe = sc.woebin_ply(test, bins=coarse_class_adj)\n",
    "\n",
    "# defining woe variables\n",
    "vars_woe = []\n",
    "for i in list(coarse_class_adj.keys()):\n",
    "    vars_woe.append(i + \"_woe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IV for variables by defined subsamples (period, product etc.)\n",
    "# sc.iv_group(train_woe,\n",
    "#             var_list = [\"age_in_years_woe\"],\n",
    "#             groupby = \"personal_status_and_sex\",\n",
    "#             y = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac91e948",
   "metadata": {},
   "source": [
    "# 5. Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3334a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "train_woe_corr = train_woe[vars_woe].corr()\n",
    "\n",
    "# # plotting correlation heatmap\n",
    "# plt.figure(figsize=(40, 24))\n",
    "# sns.heatmap(train_woe[vars_woe].corr(), cmap=\"YlGnBu\", annot=True)\n",
    "# plt.show()\n",
    "\n",
    "# automated filtering of variables using iv and correlation from the fine classing\n",
    "vars_cand_1, var_rej_corr = sc.vars_filter(\n",
    "    train,\n",
    "    coarse_class_adj,\n",
    "    corr_threshold=0.6,\n",
    "    iv_threshold=0.1\n",
    ")\n",
    "\n",
    "with pd.ExcelWriter(Path(\"5_1_correlation_analysis.xlsx\"), engine=\"xlsxwriter\") as writer:\n",
    "    train_woe_corr.to_excel(writer, sheet_name=\"train_woe_corr\", index=False)\n",
    "    var_rej_corr.to_excel(writer, sheet_name=\"correlation_rej\", index=False)\n",
    "\n",
    "# applying woe transformations on train and test samples\n",
    "train_woe = sc.woebin_ply(train[[target] + vars_cand_1], bins=coarse_class_adj)\n",
    "test_woe = sc.woebin_ply(test[[target] + vars_cand_1], bins=coarse_class_adj)\n",
    "\n",
    "# check if test_woe contains null values\n",
    "print(test_woe.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce47aa0",
   "metadata": {},
   "source": [
    "# 6. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce036a5",
   "metadata": {},
   "source": [
    "## 6.1 Initial candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c97f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining woe variables\n",
    "# list of woe variables\n",
    "vars_woe = []\n",
    "for i in vars_cand_1:\n",
    "    vars_woe.append(i + \"_woe\")\n",
    "\n",
    "# target and variables\n",
    "y_train = train_woe[target]\n",
    "X_train = train_woe[vars_woe]\n",
    "y_test = test_woe[target]\n",
    "X_test = test_woe[vars_woe]\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "# logistic regression ------\n",
    "lr = LogisticRegression(\n",
    "    penalty=\"elasticnet\",\n",
    "    C=0.03,\n",
    "    l1_ratio=0.3,\n",
    "    solver=\"saga\",\n",
    "    n_jobs=-1,\n",
    "    max_iter=5000\n",
    ")\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predicted proability\n",
    "train_pred = lr.predict_proba(X_train)[:, 1]\n",
    "test_pred = lr.predict_proba(X_test)[:, 1]\n",
    "# performance ks & roc ------\n",
    "train_perf = sc.perf_eva(y_train, train_pred, title=\"train\")\n",
    "test_perf = sc.perf_eva(y_test, test_pred, title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bad rate\n",
    "train_br = {}\n",
    "train_br[\"Total\"] = y_train.count()\n",
    "train_br[\"Bads\"] = int(y_train.sum())\n",
    "train_br[\"Bad Rate\"] = round(train_br[\"Bads\"] / train_br[\"Total\"], 4)\n",
    "# test bad rate\n",
    "test_br = {}\n",
    "test_br[\"Total\"] = y_test.count()\n",
    "test_br[\"Bads\"] = int(y_test.sum())\n",
    "test_br[\"Bad Rate\"] = round(test_br[\"Bads\"] / test_br[\"Total\"], 4)\n",
    "test_br\n",
    "# combining bad rate with performance\n",
    "perf = pd.concat(\n",
    "    {\n",
    "        \"train\": pd.Series({**train_br, **train_perf}),\n",
    "        \"test\": pd.Series({**test_br, **test_perf}),\n",
    "    },\n",
    "    axis=1,\n",
    ").convert_dtypes()\n",
    "perf = perf.loc[~perf.index.isin([\"pic\"])]\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d391db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score ------\n",
    "card = sc.scorecard(coarse_class_adj, lr, X_train.columns, start_zero=True)\n",
    "# credit score\n",
    "train_score = sc.scorecard_ply(train, card, print_step=0)\n",
    "test_score = sc.scorecard_ply(test, card, print_step=0)\n",
    "\n",
    "# calculating the weights of the variables\n",
    "scorecard_points = pd.concat(card, ignore_index=True)\n",
    "scorecard_points_vars = scorecard_points[scorecard_points['variable'] != 'basepoints']\n",
    "max_points = scorecard_points_vars.groupby('variable')['points'].max().reset_index(name='max_points')\n",
    "max_points['weight'] = max_points['max_points'] / max_points['max_points'].sum()\n",
    "\n",
    "# export to Excel\n",
    "with pd.ExcelWriter(Path(\"6_1_initial_candidate.xlsx\"), engine=\"xlsxwriter\") as writer:\n",
    "    perf.to_excel(writer, sheet_name=\"perf_train_test\", index=False)\n",
    "    scorecard_points.to_excel(writer, sheet_name=\"scorecard_points\", index=False)\n",
    "    max_points.to_excel(writer, sheet_name=\"variable_weights\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b060e",
   "metadata": {},
   "source": [
    "## 6.2 Excluding useless variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3595669-9e8d-4128-844e-7339b01eaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclusions by p value = 1\n",
    "vars_filtered = max_points[max_points['max_points'] > 10]['variable'].tolist()\n",
    "max_points[max_points['max_points'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29585c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables\n",
    "vars_cand_2 = []\n",
    "for i in vars_filtered:\n",
    "    vars_cand_2.append(i)\n",
    "\n",
    "# list of woe variables\n",
    "vars_woe = []\n",
    "for i in vars_cand_2:\n",
    "    vars_woe.append(i + \"_woe\")\n",
    "\n",
    "# target and variables\n",
    "y_train = train_woe[target]\n",
    "X_train = train_woe[vars_woe]\n",
    "y_test = test_woe[target]\n",
    "X_test = test_woe[vars_woe]\n",
    "\n",
    "# logistic regression ------\n",
    "lr = LogisticRegression(\n",
    "    penalty=\"elasticnet\",\n",
    "    C=0.03,\n",
    "    l1_ratio=0.3,\n",
    "    solver=\"saga\",\n",
    "    n_jobs=-1,\n",
    "    max_iter=5000\n",
    ")\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predicted proability\n",
    "train_pred = lr.predict_proba(X_train)[:, 1]\n",
    "test_pred = lr.predict_proba(X_test)[:, 1]\n",
    "# performance ks & roc ------\n",
    "train_perf = sc.perf_eva(y_train, train_pred, title=\"train\")\n",
    "test_perf = sc.perf_eva(y_test, test_pred, title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bad rate\n",
    "train_br = {}\n",
    "train_br[\"Total\"] = y_train.count()\n",
    "train_br[\"Bads\"] = int(y_train.sum())\n",
    "train_br[\"Bad Rate\"] = round(train_br[\"Bads\"] / train_br[\"Total\"], 4)\n",
    "# test bad rate\n",
    "test_br = {}\n",
    "test_br[\"Total\"] = y_test.count()\n",
    "test_br[\"Bads\"] = int(y_test.sum())\n",
    "test_br[\"Bad Rate\"] = round(test_br[\"Bads\"] / test_br[\"Total\"], 4)\n",
    "test_br\n",
    "# combining bad rate with performance\n",
    "perf = pd.concat(\n",
    "    {\n",
    "        \"train\": pd.Series({**train_br, **train_perf}),\n",
    "        \"test\": pd.Series({**test_br, **test_perf}),\n",
    "    },\n",
    "    axis=1,\n",
    ").convert_dtypes()\n",
    "\n",
    "perf = perf.loc[~perf.index.isin([\"pic\"])]\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score ------\n",
    "card = sc.scorecard(coarse_class_adj, lr, X_train.columns, start_zero=True)\n",
    "# credit score\n",
    "train_score = sc.scorecard_ply(train, card, print_step=0)\n",
    "test_score = sc.scorecard_ply(test, card, print_step=0)\n",
    "\n",
    "# calculating the weights of the variables\n",
    "scorecard_points = pd.concat(card, ignore_index=True)\n",
    "scorecard_points_vars = scorecard_points[scorecard_points['variable'] != 'basepoints']\n",
    "max_points = scorecard_points_vars.groupby('variable')['points'].max().reset_index(name='max_points')\n",
    "max_points['weight'] = max_points['max_points'] / max_points['max_points'].sum()\n",
    "\n",
    "# export to Excel\n",
    "with pd.ExcelWriter(Path(\"6_2_final_candidate.xlsx\"), engine=\"xlsxwriter\") as writer:\n",
    "    perf.to_excel(writer, sheet_name=\"perf_train_test\", index=False)\n",
    "    # lr_output.to_excel(writer, sheet_name=\"regr_output\", index=False)\n",
    "    scorecard_points.to_excel(writer, sheet_name=\"scorecard_points\", index=False)\n",
    "    max_points.to_excel(writer, sheet_name=\"variable_weights\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8adfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# binning visualization\n",
    "coarse_class_final = {\n",
    "    k: v for k, v in coarse_class_adj.items() if k in vars_cand_2\n",
    "}\n",
    "sc.woebin_plot(coarse_class_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse_class_vars = [k for k, v in coarse_class_adj.items() if k + \"_woe\" in vars_final]\n",
    "\n",
    "# # manual review and adjustment of binning (results are being saved to save_breaks_list and can be loaded from load_breaks_list)\n",
    "# breaks_list_final = sc.woebin_adj(\n",
    "#     train,\n",
    "#     y=target,\n",
    "#     x=[\"agro_flag\"],\n",
    "#     # load_breaks_list=\"3_5_breaks_list_adj.py\",\n",
    "#     # save_breaks_list=\"9_9_breaks_list_adj.py\",\n",
    "#     bins=coarse_class_filt,  # used in case load_breaks_list is None or not exists\n",
    "#     init_bins=fine_class,\n",
    "#     adj_all_var=True,  # False - only non-monotonic woe variables\n",
    "#     show_init_bins=True,  # True - to show the table with Fine classing results\n",
    "#     special_values=special_values,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f8e89",
   "metadata": {},
   "source": [
    "# 7. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b272f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_testing = sc.woebin_ply(smp_full, bins=coarse_class_adj, print_step=1)\n",
    "smp_testing[\"score\"] = sc.scorecard_ply(smp_full, card, print_step=0)\n",
    "print(smp_testing[vars_woe+['score','target']].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282fddc0-55a7-4457-82d7-9f8468a24135",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_testing = smp_testing[smp_testing[target].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83864d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"RepDate_end\"\n",
    "smp_testing_outcome = smp_testing[smp_testing[date].between('2020-01-31', '2024-06-30')]\n",
    "\n",
    "# adding target\n",
    "train_score[target] = train[target]\n",
    "test_score[target] = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd9265-274f-4bb4-8729-96362a1a922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.performance_testing(\n",
    "    smp_testing=smp_testing,\n",
    "    train_score=train_score,\n",
    "    test_score=test_score,\n",
    "    train_woe=train_woe,\n",
    "    test_woe=test_woe,\n",
    "    vars_woe=vars_woe,\n",
    "    target=target,\n",
    "    date_col=date,\n",
    "    groupby_col=\"housing\",\n",
    "    output_path=\"7_1_testing_results.xlsx\",\n",
    "    outcome_period=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262cb7f",
   "metadata": {},
   "source": [
    "# 8. Recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing sample for recalibration\n",
    "train_score  = sc.scorecard_ply(train, card, print_step=0)\n",
    "train_score['target'] = train['target']\n",
    "train_score['pd_regr'] = sc.pd_from_score(train_score['score'])\n",
    "\n",
    "test_score  = sc.scorecard_ply(test, card, print_step=0)\n",
    "test_score['target'] = test['target']\n",
    "test_score['pd_regr'] = sc.pd_from_score(test_score['score'])\n",
    "\n",
    "smp_calib_score = pd.concat([train_score, test_score], ignore_index=True)\n",
    "\n",
    "# assigning ratings\n",
    "bins = [0,500,540,580,620,660,700,740,780,1000]\n",
    "labels = ['4.5','4.0','3.5','3.0','2.5','2.0','1.5','1.0','0.5']\n",
    "smp_calib_score['rating'] = pd.cut(smp_calib_score['score'], bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1075ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept, slope = sc.calibration(smp_calib_score, score='score', target='target')\n",
    "print(intercept, slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1feef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_calib_score['score_new'] = smp_calib_score['score']*slope + intercept\n",
    "smp_calib_score['score_new'] = smp_calib_score['score_new'].astype(int)\n",
    "smp_calib_score['rating_new'] = pd.cut(smp_calib_score['score_new'], bins=bins, labels=labels, include_lowest=True)\n",
    "smp_calib_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
