{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6aae60",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ebf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.stats import chi2_contingency\n",
    "import scorecardpy as sc\n",
    "from scorecardpy.LogisticRegStats import LogisticRegStats\n",
    "import random as rd\n",
    "import re\n",
    "from IPython.display import display\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa21b6",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prepare ------\n",
    "# load germancredit data\n",
    "smp_full = sc.germancredit()\n",
    "smp_full['target'] = smp_full['creditability'].apply(lambda x: 1 if x == 'bad' else 0)\n",
    "smp_full.loc[0:99, 'credit.amount'] = np.nan\n",
    "smp_full.loc[100:199, 'credit.amount'] = -9999\n",
    "smp_full['credit.amount.corr'] = smp_full['credit.amount']*2 - 1000\n",
    "smp_full.loc[0:99, 'purpose'] = np.nan\n",
    "smp_full.loc[100:109, 'target'] = np.nan\n",
    "\n",
    "# Artificially multiplying the dataset\n",
    "for i in range(5):\n",
    "    smp_full = pd.concat([smp_full, smp_full])\n",
    "\n",
    "# Generate a list of all month-end dates between Jan 2020 and Sep 2025\n",
    "month_ends = pd.date_range(start=\"2020-01-31\", end=\"2025-09-30\", freq=\"ME\")\n",
    "\n",
    "# Randomly assign one of these month-end dates to each row\n",
    "np.random.seed(123)\n",
    "smp_full[\"RepDate_end\"] = np.random.choice(month_ends, size=smp_full.shape[0])\n",
    "smp_full = smp_full.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddf908",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d718b37",
   "metadata": {},
   "source": [
    "# 1. Preliminary analysis of variables (missings, outliers, concentration/distribution) - based on smp_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good/bad label\n",
    "target = \"target\"\n",
    "\n",
    "# date column (e.g. snapshot date or application date)\n",
    "date = \"RepDate_end\"\n",
    "\n",
    "# other columns that are not variables\n",
    "var_skip = [\"creditability\"]\n",
    "\n",
    "# all columns that are not variables\n",
    "var_skip_all = var_skip + [target, date]\n",
    "\n",
    "# special values for numeric variables - TBD\n",
    "special_values = [-9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap for the missing values\n",
    "# sc.miss_heatmap(smp_full, var_skip, fig_width=10, fig_height=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables checks summary\n",
    "var_cat_summary, var_num_summary, var_list = sc.expl_analysis(\n",
    "    smp_full, var_skip_all, special_values\n",
    ")\n",
    "\n",
    "display(var_cat_summary)\n",
    "display(var_num_summary)\n",
    "\n",
    "# var_max_share = var_cat_summary[var_cat_summary['Max share'] > 0.95]['Variable'].tolist() \\\n",
    "#              + var_num_summary[var_num_summary['Max share'] > 0.95]['Variable'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16676f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatment of nan - median for numeric and 'Missing' for string\n",
    "# smp_full2 = sc.nan_treatment(smp_full, x = None, var_skip = var_skip_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f668b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables distribution\n",
    "# sc.var_distr(smp_full, var_list, groupby = target, special_values = special_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of shares of missings and bads in target over time\n",
    "def nan_rate(target):\n",
    "    return sum(np.isnan(target)) / len(target)\n",
    "\n",
    "\n",
    "def bad_rate(target):\n",
    "    return sum(target == 1) / (sum(target == 0) + sum(target == 1))\n",
    "\n",
    "\n",
    "target_ot = smp_full.groupby(date)[target].agg([nan_rate, bad_rate])\n",
    "\n",
    "# dates with blank target\n",
    "pd.DataFrame(target_ot[target_ot[\"nan_rate\"] > 0][\"nan_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9640afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad rate over time\n",
    "target_ot[\"bad_rate\"].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa98a7",
   "metadata": {},
   "source": [
    "# 2. Development sample creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of the development window\n",
    "smp_dev = smp_full[smp_full[date].between('2020-01-31', '2024-06-30')]\n",
    "\n",
    "# selection of variables that will be used for the development\n",
    "smp_dev = smp_dev[var_list + [target, date]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a603d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check target\n",
    "print(smp_dev.groupby(target, dropna=False).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d42c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete records with blank target\n",
    "smp_dev = smp_dev[smp_dev[target].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split as 80/20\n",
    "train, test = sc.split_df(smp_dev, ratio=0.8, seed=123).values()\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ad203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test sample size\n",
    "query = f\"\"\"\n",
    "        select 'train' as sample, \n",
    "               sum({target}) as bads, \n",
    "               count(*) as obs, \n",
    "               sum({target})*1.00/count({target}) as BR\n",
    "        from train\n",
    "        union\n",
    "        select 'test' as sample, \n",
    "               sum({target}) as bads, \n",
    "               count(*) as obs, \n",
    "               sum({target})*1.00/count({target}) as BR\n",
    "        from test\n",
    "    \"\"\"\n",
    "# Query execution\n",
    "sqldf(query)\n",
    "# pd.DataFrame({'train':pd.Series(train.groupby('target', dropna=False).size()),\n",
    "#               'test':pd.Series(test.groupby('target', dropna=False).size())})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae9f54",
   "metadata": {},
   "source": [
    "# 3. Automated binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min bin size for fine classing\n",
    "min_perc_fine_bin = 0.05\n",
    "\n",
    "# min bin size for coarse classing\n",
    "count_distr_limit = 0.05\n",
    "\n",
    "# max number of coarse classes\n",
    "bin_num_limit = int(1 / count_distr_limit)\n",
    "\n",
    "# number of decimals for bin intervals\n",
    "bin_decimals = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8583828",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_inf = []\n",
    "# binning\n",
    "fine_class, coarse_class = sc.woebin(\n",
    "    train,\n",
    "    y=target,\n",
    "    # x = [\"age_in_years\", \"status_of_existing_checking_account\", \"foreign_worker\"],\n",
    "    var_skip=var_skip_all + var_inf,\n",
    "    special_values=special_values,\n",
    "    min_perc_fine_bin=min_perc_fine_bin,\n",
    "    count_distr_limit=count_distr_limit,\n",
    "    bin_num_limit=bin_num_limit,\n",
    "    print_step=10,\n",
    "    ignore_datetime_cols=False,\n",
    "    bin_decimals=bin_decimals,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26975e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting binning results to excel\n",
    "pd.concat(fine_class.values()).reset_index(drop=True).to_excel(\"3_1_fine_classing.xlsx\")\n",
    "pd.concat(coarse_class.values()).reset_index(drop=True).to_excel(\n",
    "    \"3_2_coarse_classing_auto.xlsx\"\n",
    ")\n",
    "\n",
    "# iv for variables after automated binning\n",
    "coarse_class_iv = sc.vars_iv(coarse_class)\n",
    "coarse_class_iv.to_excel(\"3_3_coarse_classing_auto_iv.xlsx\")\n",
    "\n",
    "\n",
    "# fine_class iv for variables after automated binning\n",
    "fine_class_iv = sc.vars_iv(fine_class)\n",
    "fine_class_iv.to_excel(\"3_3_fine_class_auto_iv.xlsx\")\n",
    "fine_class_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1da85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automated filtering of variables using iv and correlation from the fine classing\n",
    "var_list, var_rej_fine = sc.vars_filter(\n",
    "    train, fine_class, corr_threshold=0.6, iv_threshold=0.1\n",
    ")\n",
    "var_rej_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256fdd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing excluded variables from coarse_class dictionary\n",
    "coarse_class_filt = {k: v for k, v in coarse_class.items() if k in var_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928bc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning visualization\n",
    "var_show = ['status.of.existing.checking.account', 'credit.history','property']\n",
    "coarse_class_selected = {}\n",
    "# coarse_class_show = {k: v for k, v in coarse_class.items() if k in var_show}\n",
    "for k in var_show:\n",
    "    coarse_class_selected[k] = coarse_class[k]\n",
    "sc.woebin_plot(coarse_class_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_class_filt_iv = sc.vars_iv(coarse_class_filt)\n",
    "coarse_class_filt_iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea05222",
   "metadata": {},
   "source": [
    "# 4. Binning adjustments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be212913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual review and adjustment of binning (results are being saved to save_breaks_list and can be loaded from load_breaks_list)\n",
    "breaks_list = sc.woebin_adj(\n",
    "    train,\n",
    "    y=target,\n",
    "    # x = ['N103_1'],\n",
    "    load_breaks_list=\"3_5_breaks_list_adj.py\",\n",
    "    save_breaks_list=\"3_5_breaks_list_adj.py\",\n",
    "    bins=coarse_class_filt,  # used in case load_breaks_list is None or not exists\n",
    "    init_bins=fine_class,\n",
    "    adj_all_var=False,  # False - only non-monotonic woe variables\n",
    "    show_init_bins=True,  # True - to show the table with Fine classing results\n",
    "    special_values=special_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_trend_excl = [\n",
    "    'credit.amount',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse classing after manual adjustments\n",
    "_, coarse_class_adj = sc.woebin(\n",
    "    train,\n",
    "    y=target,\n",
    "    x=list(eval(breaks_list).keys()),\n",
    "    breaks_list=breaks_list,\n",
    "    var_skip=vars_trend_excl,\n",
    "    special_values=special_values,\n",
    "    min_perc_fine_bin=min_perc_fine_bin,\n",
    "    count_distr_limit=count_distr_limit,\n",
    "    bin_num_limit=bin_num_limit,\n",
    "    print_step=10,\n",
    "    ignore_datetime_cols=False,\n",
    "    bin_decimals=bin_decimals,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying woe transformations on train and test samples\n",
    "train_woe = sc.woebin_ply(train, bins=coarse_class_adj)\n",
    "test_woe = sc.woebin_ply(test, bins=coarse_class_adj)\n",
    "\n",
    "# defining woe variables\n",
    "vars_woe = []\n",
    "for i in list(coarse_class_adj.keys()):\n",
    "    vars_woe.append(i + \"_woe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results of the final coarse classing after manual adjustments !update\n",
    "pd.concat(coarse_class_adj.values()).reset_index(drop=True).to_excel(\n",
    "    \"3_6_coarse_classing_adj.xlsx\"\n",
    ")\n",
    "coarse_class_adj_iv = sc.vars_iv(coarse_class_adj)\n",
    "coarse_class_adj_iv.to_excel(\"3_7_coarse_classing_adj_iv.xlsx\")\n",
    "coarse_class_adj_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IV for variables by defined subsamples (period, product etc.)\n",
    "# sc.iv_group(train_woe,\n",
    "#             var_list = [\"age_in_years_woe\"],\n",
    "#             groupby = \"personal_status_and_sex\",\n",
    "#             y = target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac91e948",
   "metadata": {},
   "source": [
    "# 5. Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3334a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "train_woe_corr = train_woe[vars_woe].corr()\n",
    "train_woe_corr.to_excel(\"5_1_correlation_matrix.xlsx\")\n",
    "train_woe_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting correlation heatmap\n",
    "plt.figure(figsize=(40, 24))\n",
    "sns.heatmap(train_woe[vars_woe].corr(), cmap=\"YlGnBu\", annot=True)\n",
    "\n",
    "# displaying heatmap\n",
    "plt.show()\n",
    "\n",
    "# displaying heatmap\n",
    "# plt.savefig('5_2_correlation_heatmap.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automated filtering of variables using iv and correlation from the fine classing\n",
    "vars_cand_1, var_rej_corr = sc.vars_filter(\n",
    "    train,\n",
    "    coarse_class_adj,\n",
    "    corr_threshold=0.6,\n",
    "    iv_threshold=0.1,\n",
    "    save_to=\"5_2_correlation_rej.xlsx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e33c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclusions by corr > threshold\n",
    "var_rej_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d95c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying woe transformations on train and test samples\n",
    "train_woe = sc.woebin_ply(train[[target] + vars_cand_1], bins=coarse_class_adj)\n",
    "test_woe = sc.woebin_ply(test[[target] + vars_cand_1], bins=coarse_class_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_woe.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce47aa0",
   "metadata": {},
   "source": [
    "# 6. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to derive p-values\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "\n",
    "\n",
    "class LogisticRegStats:\n",
    "    \"\"\"\n",
    "    Wrapper Class for Logistic Regression which has the usual sklearn instance\n",
    "    in an attribute self.model, and pvalues, z scores and estimated\n",
    "    errors for each coefficient in\n",
    "\n",
    "    self.z_scores\n",
    "    self.p_values\n",
    "    self.sigma_estimates\n",
    "\n",
    "    as well as the negative hessian of the log Likelihood (Fisher information)\n",
    "\n",
    "    self.F_ij\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):  # ,**kwargs):\n",
    "        self.model = linear_model.LogisticRegression(*args, **kwargs)  # ,**args)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        #### Get p-values for the fitted model ####\n",
    "        denom = 2.0 * (1.0 + np.cosh(self.model.decision_function(X)))\n",
    "        denom = np.tile(denom, (X.shape[1], 1)).T\n",
    "        F_ij = np.dot((X / denom).T, X)  ## Fisher Information Matrix\n",
    "        eps = 1e-4\n",
    "        F_ij = (\n",
    "            np.dot((X / denom).T, X) + np.eye(F_ij.shape[0]) * eps\n",
    "        )  ## Fisher Information Matrix\n",
    "        Cramer_Rao = np.linalg.inv(F_ij)  ## Inverse Information Matrix\n",
    "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
    "        z_scores = (\n",
    "            self.model.coef_[0] / sigma_estimates\n",
    "        )  # z-score for eaach model coefficient\n",
    "        p_values = [\n",
    "            stat.norm.sf(abs(x)) * 2 for x in z_scores\n",
    "        ]  ### two tailed test for p-values\n",
    "\n",
    "        self.z_scores = z_scores\n",
    "        self.p_values = p_values\n",
    "        self.sigma_estimates = sigma_estimates\n",
    "        self.F_ij = F_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce036a5",
   "metadata": {},
   "source": [
    "## 6.1 Initial candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c97f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining woe variables\n",
    "# list of woe variables\n",
    "vars_woe = []\n",
    "for i in vars_cand_1:\n",
    "    vars_woe.append(i + \"_woe\")\n",
    "\n",
    "# target and variables\n",
    "y_train = train_woe[target]\n",
    "X_train = train_woe[vars_woe]\n",
    "y_test = test_woe[target]\n",
    "X_test = test_woe[vars_woe]\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n",
    "# logistic regression ------\n",
    "lr = LogisticRegression(penalty=\"l1\", C=0.9, solver=\"saga\", n_jobs=-1)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predicted proability\n",
    "train_pred = lr.predict_proba(X_train)[:, 1]\n",
    "test_pred = lr.predict_proba(X_test)[:, 1]\n",
    "# performance ks & roc ------\n",
    "train_perf = sc.perf_eva(y_train, train_pred, title=\"train\")\n",
    "test_perf = sc.perf_eva(y_test, test_pred, title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bad rate\n",
    "train_br = {}\n",
    "train_br[\"Total\"] = y_train.count()\n",
    "train_br[\"Bads\"] = int(y_train.sum())\n",
    "train_br[\"Bad Rate\"] = round(train_br[\"Bads\"] / train_br[\"Total\"], 4)\n",
    "# test bad rate\n",
    "test_br = {}\n",
    "test_br[\"Total\"] = y_test.count()\n",
    "test_br[\"Bads\"] = int(y_test.sum())\n",
    "test_br[\"Bad Rate\"] = round(test_br[\"Bads\"] / test_br[\"Total\"], 4)\n",
    "test_br\n",
    "# combining bad rate with performance\n",
    "perf = pd.concat(\n",
    "    {\n",
    "        \"train\": pd.Series({**train_br, **train_perf}),\n",
    "        \"test\": pd.Series({**test_br, **test_perf}),\n",
    "    },\n",
    "    axis=1,\n",
    ").convert_dtypes()\n",
    "perf = perf.loc[~perf.index.isin([\"pic\"])]\n",
    "perf.to_excel(\"6_1_1_perf_train_test.xlsx\")\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression with stats\n",
    "lr2 = LogisticRegStats(penalty=\"l1\", C=0.9, solver=\"saga\", n_jobs=-1)\n",
    "lr2.fit(X_train, y_train)\n",
    "\n",
    "# calculating p-values and exporting to excel\n",
    "lr_output = pd.DataFrame(\n",
    "    {\n",
    "        \"Variable\": [\"intercept\"] + X_train.columns.tolist(),\n",
    "        \"Coefficient\": [lr2.model.intercept_[0]] + lr2.model.coef_[0].tolist(),\n",
    "        \"P-value\": [0] + lr2.p_values,\n",
    "    }\n",
    ")\n",
    "\n",
    "lr_output.to_excel(\"6_1_2_regr_output.xlsx\")\n",
    "lr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d391db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score ------\n",
    "card = sc.scorecard(coarse_class_adj, lr, X_train.columns, start_zero=True)\n",
    "# credit score\n",
    "train_score = sc.scorecard_ply(train, card, print_step=0)\n",
    "test_score = sc.scorecard_ply(test, card, print_step=0)\n",
    "# output to excel\n",
    "scorecard_points = pd.concat(card, ignore_index=True)\n",
    "scorecard_points.to_excel(\"6_1_3_scorecard_points.xlsx\", sheet_name=\"scorecard_points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b060e",
   "metadata": {},
   "source": [
    "## 6.2 Excluding p-values > 10% & coefficient > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29585c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclusions by p value = 1\n",
    "vars_pval_excl = (\n",
    "    lr_output[\"Variable\"][lr_output[\"P-value\"] > 0.1].to_list()\n",
    "    + lr_output[\"Variable\"][lr_output[\"Coefficient\"] > 0].to_list()\n",
    ")\n",
    "\n",
    "# list of variables\n",
    "vars_cand_2 = []\n",
    "for i in vars_cand_1:\n",
    "    if i + \"_woe\" not in vars_pval_excl:\n",
    "        vars_cand_2.append(i)\n",
    "\n",
    "# list of woe variables\n",
    "vars_woe = []\n",
    "for i in vars_cand_2:\n",
    "    vars_woe.append(i + \"_woe\")\n",
    "\n",
    "# target and variables\n",
    "y_train = train_woe[target]\n",
    "X_train = train_woe[vars_woe]\n",
    "y_test = test_woe[target]\n",
    "X_test = test_woe[vars_woe]\n",
    "\n",
    "# logistic regression ------\n",
    "lr = LogisticRegression(penalty=\"l1\", C=0.9, solver=\"saga\", n_jobs=-1)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# predicted proability\n",
    "train_pred = lr.predict_proba(X_train)[:, 1]\n",
    "test_pred = lr.predict_proba(X_test)[:, 1]\n",
    "# performance ks & roc ------\n",
    "train_perf = sc.perf_eva(y_train, train_pred, title=\"train\")\n",
    "test_perf = sc.perf_eva(y_test, test_pred, title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bad rate\n",
    "train_br = {}\n",
    "train_br[\"Total\"] = y_train.count()\n",
    "train_br[\"Bads\"] = int(y_train.sum())\n",
    "train_br[\"Bad Rate\"] = round(train_br[\"Bads\"] / train_br[\"Total\"], 4)\n",
    "# test bad rate\n",
    "test_br = {}\n",
    "test_br[\"Total\"] = y_test.count()\n",
    "test_br[\"Bads\"] = int(y_test.sum())\n",
    "test_br[\"Bad Rate\"] = round(test_br[\"Bads\"] / test_br[\"Total\"], 4)\n",
    "test_br\n",
    "# combining bad rate with performance\n",
    "perf = pd.concat(\n",
    "    {\n",
    "        \"train\": pd.Series({**train_br, **train_perf}),\n",
    "        \"test\": pd.Series({**test_br, **test_perf}),\n",
    "    },\n",
    "    axis=1,\n",
    ").convert_dtypes()\n",
    "\n",
    "perf = perf.loc[~perf.index.isin([\"pic\"])]\n",
    "perf.to_excel(\"6_2_1_perf_train_test.xlsx\")\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8793183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression with stats\n",
    "lr2 = LogisticRegStats(penalty=\"l1\", C=0.9, solver=\"saga\", n_jobs=-1)\n",
    "lr2.fit(X_train, y_train)\n",
    "\n",
    "# calculating p-values and exportign to excel\n",
    "lr_output = pd.DataFrame(\n",
    "    {\n",
    "        \"Variable\": [\"intercept\"] + X_train.columns.tolist(),\n",
    "        \"Coefficient\": [lr2.model.intercept_[0]] + lr2.model.coef_[0].tolist(),\n",
    "        \"P-value\": [0] + lr2.p_values,\n",
    "    }\n",
    ")\n",
    "\n",
    "lr_output.to_excel(\"6_2_2_regr_output.xlsx\")\n",
    "lr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    lr_output[\"Variable\"][lr_output[\"P-value\"] > 0.1].to_list()\n",
    "    + lr_output[\"Variable\"][lr_output[\"Coefficient\"] > 0].to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score ------\n",
    "card = sc.scorecard(coarse_class_adj, lr, X_train.columns, start_zero=True)\n",
    "# credit score\n",
    "train_score = sc.scorecard_ply(train, card, print_step=0)\n",
    "test_score = sc.scorecard_ply(test, card, print_step=0)\n",
    "# output to excel\n",
    "scorecard_points = pd.concat(card, ignore_index=True)\n",
    "\n",
    "# calculating the weights of the variables\n",
    "scorecard_points_vars = scorecard_points[scorecard_points['variable'] != 'basepoints']\n",
    "max_points = scorecard_points_vars.groupby('variable')['points'].max().reset_index(name='max_points')\n",
    "max_points['weight'] = max_points['max_points'] / max_points['max_points'].sum()\n",
    "\n",
    "# export to Excel\n",
    "writer = pd.ExcelWriter(\"6_2_3_scorecard_points.xlsx\", engine=\"xlsxwriter\")\n",
    "scorecard_points.to_excel(writer, sheet_name=\"scorecard_points\")\n",
    "max_points.to_excel(writer, sheet_name=\"variable_weights\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8adfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vars_final = lr_output[\"Variable\"].to_list()\n",
    "# binning visualization\n",
    "coarse_class_final = {\n",
    "    k: v for k, v in coarse_class_adj.items() if k + \"_woe\" in vars_final\n",
    "}\n",
    "sc.woebin_plot(coarse_class_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse_class_vars = [k for k, v in coarse_class_adj.items() if k + \"_woe\" in vars_final]\n",
    "\n",
    "# # manual review and adjustment of binning (results are being saved to save_breaks_list and can be loaded from load_breaks_list)\n",
    "# breaks_list_final = sc.woebin_adj(\n",
    "#     train,\n",
    "#     y=target,\n",
    "#     x=[\"agro_flag\"],\n",
    "#     # load_breaks_list=\"3_5_breaks_list_adj.py\",\n",
    "#     # save_breaks_list=\"9_9_breaks_list_adj.py\",\n",
    "#     bins=coarse_class_filt,  # used in case load_breaks_list is None or not exists\n",
    "#     init_bins=fine_class,\n",
    "#     adj_all_var=True,  # False - only non-monotonic woe variables\n",
    "#     show_init_bins=True,  # True - to show the table with Fine classing results\n",
    "#     special_values=special_values,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f8e89",
   "metadata": {},
   "source": [
    "# 7. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b272f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_testing_score = sc.woebin_ply(smp_full, bins=coarse_class_adj, print_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa56c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_testing_score[\"score\"] = sc.scorecard_ply(smp_full, card, print_step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5999c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smp_testing_score[vars_woe+['score','target']].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282fddc0-55a7-4457-82d7-9f8468a24135",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_testing_score = smp_testing_score[smp_testing_score[target].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83864d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"RepDate_end\"\n",
    "smp_dev_score = smp_testing_score[smp_testing_score[date].between('2020-01-31', '2024-06-30')]\n",
    "\n",
    "# adding target\n",
    "train_score[target] = train[target]\n",
    "test_score[target] = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbec85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bad Rate over time\n",
    "gini_ot = smp_dev_score[[date, target]].groupby([date]).agg([\"count\", \"sum\"])\n",
    "gini_ot = gini_ot.rename(columns={\"count\": \"Total\", \"sum\": \"Bads\"})\n",
    "gini_ot.columns = gini_ot.columns.droplevel(0)\n",
    "gini_ot[\"Bad Rate\"] = gini_ot[\"Bads\"] / gini_ot[\"Total\"]\n",
    "# adding Gini over time\n",
    "gini_ot[\"Gini\"] = sc.gini_over_time(smp_dev_score, target, [\"score\"], date)\n",
    "\n",
    "# Gini for vars train/test\n",
    "gini_vars_train = sc.gini_vars(train_woe, target, vars_woe, \"Train\")\n",
    "gini_vars_test = sc.gini_vars(test_woe, target, vars_woe, \"Test\")\n",
    "gini_vars_train_test = pd.merge(gini_vars_train, gini_vars_test, on=\"Variable\")\n",
    "\n",
    "# Gini for vars over time\n",
    "gini_vars_ot = sc.gini_over_time(smp_dev_score, target, vars_woe, date)\n",
    "\n",
    "# defining score ranges on train sample\n",
    "_, brk = pd.cut(train_score[\"score\"], bins=10, retbins=True, duplicates=\"drop\")\n",
    "brk = brk.round(decimals=2)\n",
    "brk = list(\n",
    "    filter(\n",
    "        lambda x: x > np.nanmin(train_score[\"score\"])\n",
    "        and x < np.nanmax(train_score[\"score\"]),\n",
    "        brk,\n",
    "    )\n",
    ")\n",
    "brk = (\n",
    "    [np.nanmin(smp_testing_score[\"score\"])]\n",
    "    + sorted(brk)\n",
    "    + [np.nanmax(smp_testing_score[\"score\"])]\n",
    ")\n",
    "# applying score ranges on train, test adn full samples\n",
    "train_score[\"score_range\"] = pd.cut(\n",
    "    train_score[\"score\"], bins=brk, include_lowest=False\n",
    ")\n",
    "test_score[\"score_range\"] = pd.cut(test_score[\"score\"], bins=brk, include_lowest=False)\n",
    "smp_testing_score[\"score_range\"] = pd.cut(\n",
    "    smp_testing_score[\"score\"], bins=brk, include_lowest=False\n",
    ")\n",
    "# score distribution for train/test\n",
    "train_distr = sc.score_distr(train_score, target, \"score\", \"score_range\")\n",
    "test_distr = sc.score_distr(test_score, target, \"score\", \"score_range\")\n",
    "\n",
    "# PSI over time (score_range)\n",
    "psi_ot = sc.psi_over_time(train_score, smp_testing_score, [\"score_range\"], date)\n",
    "\n",
    "# PSI for WoE variables over time\n",
    "psi_vars_ot = sc.psi_over_time(train_woe, smp_testing_score, vars_woe, date)\n",
    "\n",
    "# calculating hhi for train/test\n",
    "train_hhi = sc.hhi(train_score[\"score_range\"].astype(str))\n",
    "test_hhi = sc.hhi(test_score[\"score_range\"].astype(str))\n",
    "hhi_train_test = pd.DataFrame({\"train\": [train_hhi], \"test\": [test_hhi]}, index=[\"hhi\"])\n",
    "\n",
    "# calculating hhi over time\n",
    "hhi_ot = smp_testing_score.groupby(date).agg({\"score_range\": sc.hhi})\n",
    "hhi_ot = hhi_ot.rename(columns={\"score_range\": \"HHI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930420b1-547b-476b-8be6-1d61b7fc0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assign ratings ---\n",
    "bins = [0, 499, 539, 579, 619, 659, 699, 739, 779, 999]\n",
    "labels = [\"4.5\", \"4.0\", \"3.5\", \"3.0\", \"2.5\", \"2.0\", \"1.5\", \"1.0\", \"0.5\"]\n",
    "\n",
    "# Always use .loc when assigning to avoid SettingWithCopyWarning\n",
    "smp_dev_score = smp_dev_score.copy()\n",
    "smp_testing_score = smp_testing_score.copy()\n",
    "\n",
    "smp_dev_score.loc[:, \"rating\"] = pd.cut(\n",
    "    smp_dev_score[\"score\"], bins=bins, labels=labels, include_lowest=True\n",
    ")\n",
    "smp_testing_score.loc[:, \"rating\"] = pd.cut(\n",
    "    smp_testing_score[\"score\"], bins=bins, labels=labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# --- DR by rating on dev sample ---\n",
    "DR_rating = (\n",
    "    smp_dev_score[[\"rating\", target]]\n",
    "    .groupby(\"rating\", observed=True)\n",
    "    .agg([\"count\", \"sum\"])\n",
    ")\n",
    "DR_rating.columns = DR_rating.columns.droplevel(0)\n",
    "DR_rating = DR_rating.rename(columns={\"count\": \"Total\", \"sum\": \"Bads\"})\n",
    "DR_rating[\"DR\"] = DR_rating[\"Bads\"] / DR_rating[\"Total\"]\n",
    "\n",
    "# --- DR by rating over time on full sample ---\n",
    "DR_rating_ot = (\n",
    "    smp_testing_score[[date, \"rating\", target]]\n",
    "    .groupby([date, \"rating\"], observed=True)\n",
    "    .agg([\"count\", \"sum\"])\n",
    ")\n",
    "DR_rating_ot.columns = DR_rating_ot.columns.droplevel(0)\n",
    "DR_rating_ot = DR_rating_ot.rename(columns={\"count\": \"Total\", \"sum\": \"Bads\"})\n",
    "DR_rating_ot = DR_rating_ot.reset_index()\n",
    "DR_rating_ot[\"DR\"] = DR_rating_ot[\"Bads\"] / DR_rating_ot[\"Total\"]\n",
    "\n",
    "# --- Set DR to NaN for last 12 months ---\n",
    "sorted_date = sorted(DR_rating_ot[date].unique())\n",
    "DR_rating_ot.loc[DR_rating_ot[date].isin(sorted_date[-12:]), \"DR\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting results to excel\n",
    "writer = pd.ExcelWriter(\"7_1_testing_results.xlsx\", engine=\"xlsxwriter\")\n",
    "gini_ot.to_excel(writer, sheet_name=\"Gini_OT\")\n",
    "gini_vars_train_test.to_excel(writer, sheet_name=\"Gini_Vars\")\n",
    "gini_vars_ot.to_excel(writer, sheet_name=\"Gini_Vars_OT\")\n",
    "train_distr.to_excel(writer, sheet_name=\"Distr_Train\")\n",
    "test_distr.to_excel(writer, sheet_name=\"Distr_Test\")\n",
    "psi_ot.to_excel(writer, sheet_name=\"PSI_OT\")\n",
    "psi_vars_ot.to_excel(writer, sheet_name=\"PSI_Vars_OT\")\n",
    "hhi_train_test.to_excel(writer, sheet_name=\"HHI\")\n",
    "hhi_ot.to_excel(writer, sheet_name=\"HHI_OT\")\n",
    "DR_rating.to_excel(writer, sheet_name=\"DR_rating\")\n",
    "DR_rating_ot.to_excel(writer, sheet_name=\"DR_rating_ot\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc90c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DR vs PD by product over time\n",
    "smp_dev_score[\"pd\"] = sc.pd_from_score(smp_dev_score[\"score\"])\n",
    "\n",
    "dr_ot = (\n",
    "    smp_dev_score[[date, \"housing\", target]]\n",
    "    .groupby([date, \"housing\"], observed=True)\n",
    "    .agg([\"count\", \"sum\"])\n",
    ")\n",
    "dr_ot = dr_ot.rename(columns={\"count\": \"Total\", \"sum\": \"Bads\"})\n",
    "dr_ot.columns = dr_ot.columns.droplevel(0)\n",
    "dr_ot[\"Bad Rate\"] = dr_ot[\"Bads\"] / dr_ot[\"Total\"]\n",
    "\n",
    "dr_ot2 = (\n",
    "    smp_dev_score[[date, \"housing\", \"pd\"]]\n",
    "    .groupby([date, \"housing\"], observed=True)\n",
    "    .agg([\"count\", \"sum\"])\n",
    ")\n",
    "dr_ot2 = dr_ot2.rename(columns={\"count\": \"Total\", \"sum\": \"Bads\"})\n",
    "dr_ot2.columns = dr_ot2.columns.droplevel(0)\n",
    "dr_ot2[\"PD\"] = dr_ot2[\"Bads\"] / dr_ot2[\"Total\"]\n",
    "dr_ot[\"PD\"] = dr_ot2[\"PD\"]\n",
    "\n",
    "dr_ot = dr_ot.swaplevel()\n",
    "\n",
    "dr_ot.to_excel(\"7_2_DR_ot_products.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262cb7f",
   "metadata": {},
   "source": [
    "# 8. Recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing sample for recalibration\n",
    "train_score  = sc.scorecard_ply(train, card, print_step=0)\n",
    "train_score['target'] = train['target']\n",
    "train_score['pd_regr'] = sc.pd_from_score(train_score['score'])\n",
    "\n",
    "test_score  = sc.scorecard_ply(test, card, print_step=0)\n",
    "test_score['target'] = test['target']\n",
    "test_score['pd_regr'] = sc.pd_from_score(test_score['score'])\n",
    "\n",
    "smp_calib_score = pd.concat([train_score, test_score], ignore_index=True)\n",
    "\n",
    "# assigning ratings\n",
    "bins = [0,500,540,580,620,660,700,740,780,1000]\n",
    "labels = ['4.5','4.0','3.5','3.0','2.5','2.0','1.5','1.0','0.5']\n",
    "smp_calib_score['rating'] = pd.cut(smp_calib_score['score'], bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1075ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept, slope = sc.calibration(smp_calib_score, score='score', target='target')\n",
    "print(intercept, slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1feef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_calib_score['score_new'] = smp_calib_score['score']*slope + intercept\n",
    "smp_calib_score['score_new'] = smp_calib_score['score_new'].astype(int)\n",
    "smp_calib_score['rating_new'] = pd.cut(smp_calib_score['score_new'], bins=bins, labels=labels, include_lowest=True)\n",
    "smp_calib_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
